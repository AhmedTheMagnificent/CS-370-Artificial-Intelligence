{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in a:\\anaconda\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: opencv-python in a:\\anaconda\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: mediapipe in a:\\anaconda\\lib\\site-packages (0.10.11)\n",
      "Requirement already satisfied: matplotlib in a:\\anaconda\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: scikit-learn in a:\\anaconda\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in a:\\anaconda\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in a:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in a:\\anaconda\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: jax in a:\\anaconda\\lib\\site-packages (from mediapipe) (0.4.26)\n",
      "Requirement already satisfied: opencv-contrib-python in a:\\anaconda\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in a:\\anaconda\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in a:\\anaconda\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in a:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in a:\\anaconda\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in a:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in a:\\anaconda\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in a:\\anaconda\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ahmed\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in a:\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in a:\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in a:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in a:\\anaconda\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in a:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: pycparser in a:\\anaconda\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: rich in a:\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in a:\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in a:\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in a:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in a:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in a:\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in a:\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in a:\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in a:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in a:\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in a:\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in a:\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow opencv-python mediapipe matplotlib scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHolistic = mp.solutions.holistic\n",
    "mpDrawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipeDetection(image, model):\n",
    "  image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "  image.flags.writeable = False\n",
    "  results = model.process(image)\n",
    "  image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "  image.flags.writeable = True\n",
    "  return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLandmarks(image, results):\n",
    "    FACE_CONNECTIONS = [\n",
    "    (10, 338), (338, 297), (297, 332), (332, 284), (284, 251), (251, 389), (389, 356), (356, 454), \n",
    "    (454, 323), (323, 361), (361, 288), (288, 397), (397, 365), (365, 379), (379, 378), (378, 400), \n",
    "    (400, 377), (377, 152), (152, 148), (148, 176), (176, 149), (149, 150), (150, 136), (136, 172), \n",
    "    (172, 58), (58, 132), (132, 93), (93, 234), (234, 127), (127, 162), (162, 21), (21, 54), (54, 103), \n",
    "    (103, 67), (67, 109), (109, 10)\n",
    "    ]\n",
    "    mpDrawing.draw_landmarks(image, results.face_landmarks,FACE_CONNECTIONS)\n",
    "    mpDrawing.draw_landmarks(image, results.pose_landmarks, mpHolistic.POSE_CONNECTIONS)\n",
    "    mpDrawing.draw_landmarks(image, results.right_hand_landmarks, mpHolistic.HAND_CONNECTIONS)\n",
    "    mpDrawing.draw_landmarks(image, results.left_hand_landmarks, mpHolistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawStyledLandmarks(image, results):\n",
    "    FACE_CONNECTIONS = [\n",
    "    (10, 338), (338, 297), (297, 332), (332, 284), (284, 251), (251, 389), (389, 356), (356, 454), \n",
    "    (454, 323), (323, 361), (361, 288), (288, 397), (397, 365), (365, 379), (379, 378), (378, 400), \n",
    "    (400, 377), (377, 152), (152, 148), (148, 176), (176, 149), (149, 150), (150, 136), (136, 172), \n",
    "    (172, 58), (58, 132), (132, 93), (93, 234), (234, 127), (127, 162), (162, 21), (21, 54), (54, 103), \n",
    "    (103, 67), (67, 109), (109, 10)\n",
    "    ]\n",
    "    mpDrawing.draw_landmarks(image, results.face_landmarks,FACE_CONNECTIONS,\n",
    "                             mpDrawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                             mpDrawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1))\n",
    "    mpDrawing.draw_landmarks(image, results.pose_landmarks, mpHolistic.POSE_CONNECTIONS,\n",
    "                             mpDrawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                             mpDrawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2))\n",
    "    mpDrawing.draw_landmarks(image, results.right_hand_landmarks, mpHolistic.HAND_CONNECTIONS,\n",
    "                             mpDrawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mpDrawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2))\n",
    "    mpDrawing.draw_landmarks(image, results.left_hand_landmarks, mpHolistic.HAND_CONNECTIONS,\n",
    "                             mpDrawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mpDrawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "with mpHolistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
    "  while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    image, results = mediapipeDetection(frame, holistic)\n",
    "    drawStyledLandmarks(image, results)\n",
    "    cv.imshow(\"OpenCV Feed\", image)\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "      break\n",
    "  cap.release()\n",
    "  cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(132)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "    return np.concatenate([pose,face,lh,rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MP_Data')\n",
    "actions = np.array(['hello', 'thanks','i love you'])\n",
    "noSequences = 30\n",
    "sequenceLength = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(noSequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH,action,str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32ma:\\anaconda\\Lib\\site-packages\\keras\\src\\models\\sequential.py:74\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(layer, rebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32ma:\\anaconda\\Lib\\site-packages\\keras\\src\\models\\sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32ma:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\layer.py:222\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m--> 222\u001b[0m         \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[1;32ma:\\anaconda\\Lib\\site-packages\\keras\\src\\models\\sequential.py:180\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 180\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32ma:\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32ma:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:186\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mallow_last_axis_squeeze:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m>\u001b[39m spec\u001b[38;5;241m.\u001b[39mmax_ndim:\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True, activation=\"relu\", input_shape = ()),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, activation=\"relu\"),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(actions.shape[0], activation=\"softmax\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"A:\\\\archive (1)\\\\\"\n",
    "wlasl_df = pd.read_json(main_path + \"WLASL_v0.3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlasl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoIDs(jsonList):\n",
    "    videoIDs = []\n",
    "    for i in jsonList:\n",
    "        videoID = i['video_id']\n",
    "        if os.path.exists(f'{main_path}videos/{videoID}.mp4'):\n",
    "            videoIDs.append(videoID)\n",
    "    return videoIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(main_path+'WLASL_v0.3.json', 'r') as dataFile:\n",
    "    jsonData = dataFile.read()\n",
    "\n",
    "instance_json = json.loads(jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['69241', '07069', '07068', '07070', '07099', '07074']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getVideoIDs(instance_json[0]['instances']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlasl_df[\"video_ids\"] = wlasl_df[\"instances\"].apply(getVideoIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "      <th>video_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...</td>\n",
       "      <td>[69241, 07069, 07068, 07070, 07099, 07074]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "      <td>[{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[69302, 65539, 17710, 17733, 65540, 17734, 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[12328, 12312, 12311, 12338, 12313, 12314, 123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[05728, 05749, 05750, 05729, 05730, 65167, 057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[09848, 09869, 09849, 09850, 09851, 65328, 09854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>washington</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62393, 62394, 62395, 62396, 62398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>waterfall</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62488, 62489, 62490, 62492, 62493]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>weigh</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62782, 62783, 62785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>[{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[63044, 63046, 63047, 63050]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>whistle</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[63186, 63188, 63190]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gloss                                          instances  \\\n",
       "0           book  [{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...   \n",
       "1          drink  [{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...   \n",
       "2       computer  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "3         before  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "4          chair  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "...          ...                                                ...   \n",
       "1995  washington  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1996   waterfall  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1997       weigh  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1998  wheelchair  [{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...   \n",
       "1999     whistle  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "\n",
       "                                              video_ids  \n",
       "0            [69241, 07069, 07068, 07070, 07099, 07074]  \n",
       "1     [69302, 65539, 17710, 17733, 65540, 17734, 177...  \n",
       "2     [12328, 12312, 12311, 12338, 12313, 12314, 123...  \n",
       "3     [05728, 05749, 05750, 05729, 05730, 65167, 057...  \n",
       "4     [09848, 09869, 09849, 09850, 09851, 65328, 09854]  \n",
       "...                                                 ...  \n",
       "1995                [62393, 62394, 62395, 62396, 62398]  \n",
       "1996                [62488, 62489, 62490, 62492, 62493]  \n",
       "1997                              [62782, 62783, 62785]  \n",
       "1998                       [63044, 63046, 63047, 63050]  \n",
       "1999                              [63186, 63188, 63190]  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlasl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions= np.array(wlasl_df['gloss'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('MP_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action, videos in zip(actions, wlasl_df['video_ids']):\n",
    "    for sequence, video_id in enumerate(videos):\n",
    "        directory_path = os.path.join(DATA_PATH, action, str(sequence))\n",
    "        os.makedirs(directory_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: 69241, Total Frames: 75\n",
      "Video ID: 07069, Total Frames: 30\n",
      "End of video.\n",
      "Video ID: 07068, Total Frames: 68\n",
      "End of video.\n",
      "Video ID: 07070, Total Frames: 86\n",
      "End of video.\n",
      "Video ID: 07099, Total Frames: 87\n",
      "End of video.\n",
      "Video ID: 07074, Total Frames: 41\n",
      "End of video.\n",
      "Video ID: 69302, Total Frames: 77\n",
      "End of video.\n",
      "Video ID: 65539, Total Frames: 44\n",
      "End of video.\n",
      "Video ID: 17710, Total Frames: 70\n",
      "End of video.\n",
      "Video ID: 17733, Total Frames: 93\n",
      "End of video.\n",
      "Video ID: 65540, Total Frames: 46\n",
      "End of video.\n",
      "Video ID: 17734, Total Frames: 89\n",
      "End of video.\n",
      "Video ID: 17711, Total Frames: 81\n",
      "End of video.\n",
      "Video ID: 17712, Total Frames: 43\n",
      "End of video.\n",
      "Video ID: 17713, Total Frames: 91\n",
      "End of video.\n",
      "Video ID: 17709, Total Frames: 105\n",
      "End of video.\n",
      "Video ID: 17720, Total Frames: 41\n",
      "End of video.\n",
      "Video ID: 17721, Total Frames: 49\n",
      "End of video.\n",
      "Video ID: 17722, Total Frames: 49\n",
      "End of video.\n",
      "Video ID: 17723, Total Frames: 60\n",
      "End of video.\n",
      "Video ID: 17724, Total Frames: 30\n",
      "End of video.\n",
      "Video ID: 12328, Total Frames: 88\n",
      "End of video.\n",
      "Video ID: 12312, Total Frames: 101\n",
      "End of video.\n",
      "Video ID: 12311, Total Frames: 72\n",
      "End of video.\n",
      "Video ID: 12338, Total Frames: 107\n",
      "End of video.\n",
      "Video ID: 12313, Total Frames: 81\n",
      "End of video.\n",
      "Video ID: 12314, Total Frames: 43\n",
      "End of video.\n",
      "Video ID: 12315, Total Frames: 57\n",
      "End of video.\n",
      "Video ID: 12316, Total Frames: 43\n",
      "End of video.\n",
      "Video ID: 12317, Total Frames: 53\n",
      "End of video.\n",
      "Video ID: 12318, Total Frames: 45\n",
      "End of video.\n",
      "Video ID: 12319, Total Frames: 40\n",
      "End of video.\n",
      "Video ID: 12320, Total Frames: 102\n",
      "End of video.\n",
      "Video ID: 12326, Total Frames: 73\n",
      "End of video.\n",
      "Video ID: 12327, Total Frames: 46\n",
      "End of video.\n",
      "Video ID: 05728, Total Frames: 26\n",
      "End of video.\n",
      "Video ID: 05749, Total Frames: 90\n",
      "End of video.\n",
      "Video ID: 05750, Total Frames: 100\n",
      "End of video.\n",
      "Video ID: 05729, Total Frames: 52\n",
      "End of video.\n",
      "Video ID: 05730, Total Frames: 31\n",
      "End of video.\n",
      "Video ID: 65167, Total Frames: 58\n",
      "End of video.\n",
      "Video ID: 05731, Total Frames: 45\n",
      "End of video.\n",
      "Video ID: 05732, Total Frames: 86\n",
      "End of video.\n",
      "Video ID: 05733, Total Frames: 108\n",
      "End of video.\n",
      "Video ID: 05734, Total Frames: 81\n",
      "End of video.\n",
      "Video ID: 05727, Total Frames: 87\n",
      "End of video.\n",
      "Video ID: 05739, Total Frames: 52\n",
      "End of video.\n",
      "Video ID: 05740, Total Frames: 50\n",
      "End of video.\n",
      "Video ID: 05741, Total Frames: 31\n",
      "End of video.\n",
      "Video ID: 05742, Total Frames: 28\n",
      "End of video.\n",
      "Video ID: 05743, Total Frames: 50\n",
      "End of video.\n",
      "Video ID: 09848, Total Frames: 96\n",
      "End of video.\n",
      "Video ID: 09869, Total Frames: 93\n",
      "End of video.\n",
      "Video ID: 09849, Total Frames: 81\n",
      "End of video.\n",
      "Video ID: 09850, Total Frames: 31\n",
      "End of video.\n",
      "Video ID: 09851, Total Frames: 92\n",
      "End of video.\n",
      "Video ID: 65328, Total Frames: 59\n",
      "End of video.\n",
      "Video ID: 09854, Total Frames: 32\n",
      "End of video.\n",
      "Video ID: 69345, Total Frames: 67\n",
      "End of video.\n",
      "Video ID: 24955, Total Frames: 61\n",
      "End of video.\n",
      "Video ID: 24956, Total Frames: 46\n",
      "End of video.\n",
      "Video ID: 24941, Total Frames: 66\n",
      "End of video.\n",
      "Video ID: 24960, Total Frames: 47\n",
      "End of video.\n",
      "Video ID: 24961, Total Frames: 47\n",
      "End of video.\n",
      "Video ID: 24962, Total Frames: 43\n",
      "End of video.\n",
      "Video ID: 65824, Total Frames: 41\n",
      "End of video.\n",
      "Video ID: 24973, Total Frames: 108\n",
      "End of video.\n",
      "Video ID: 24943, Total Frames: 61\n",
      "End of video.\n",
      "Video ID: 24946, Total Frames: 33\n",
      "End of video.\n",
      "Video ID: 24947, Total Frames: 63\n",
      "End of video.\n",
      "Video ID: 24940, Total Frames: 88\n",
      "End of video.\n",
      "Video ID: 24952, Total Frames: 34\n",
      "End of video.\n",
      "Video ID: 24954, Total Frames: 61\n",
      "End of video.\n",
      "Video ID: 11310, Total Frames: 89\n",
      "End of video.\n",
      "Video ID: 11330, Total Frames: 83\n",
      "End of video.\n",
      "Video ID: 11311, Total Frames: 93\n",
      "End of video.\n",
      "Video ID: 11313, Total Frames: 36\n",
      "End of video.\n",
      "Video ID: 11309, Total Frames: 67\n",
      "End of video.\n",
      "Video ID: 69534, Total Frames: 63\n",
      "End of video.\n",
      "Video ID: 63242, Total Frames: 86\n",
      "End of video.\n",
      "Video ID: 63226, Total Frames: 67\n",
      "End of video.\n",
      "Video ID: 63227, Total Frames: 36\n",
      "End of video.\n",
      "Video ID: 63228, Total Frames: 40\n",
      "End of video.\n",
      "Video ID: 63229, Total Frames: 47\n",
      "End of video.\n",
      "Video ID: 63230, Total Frames: 61\n",
      "End of video.\n",
      "Video ID: 63231, Total Frames: 93\n",
      "End of video.\n",
      "Video ID: 66778, Total Frames: 58\n",
      "End of video.\n",
      "Video ID: 63232, Total Frames: 155\n",
      "End of video.\n",
      "Video ID: 66779, Total Frames: 54\n",
      "End of video.\n",
      "Video ID: 63225, Total Frames: 111\n",
      "End of video.\n",
      "Video ID: 63236, Total Frames: 46\n",
      "End of video.\n",
      "Video ID: 63237, Total Frames: 47\n",
      "End of video.\n",
      "Video ID: 08929, Total Frames: 82\n",
      "End of video.\n",
      "Video ID: 08916, Total Frames: 88\n",
      "End of video.\n",
      "Video ID: 08917, Total Frames: 32\n",
      "End of video.\n",
      "Video ID: 08918, Total Frames: 30\n",
      "End of video.\n",
      "Video ID: 08919, Total Frames: 86\n",
      "End of video.\n",
      "Video ID: 08920, Total Frames: 75\n",
      "End of video.\n",
      "Video ID: 08921, Total Frames: 58\n",
      "End of video.\n",
      "Video ID: 65298, Total Frames: 59\n",
      "End of video.\n",
      "Video ID: 08924, Total Frames: 28\n",
      "End of video.\n",
      "Video ID: 65299, Total Frames: 62\n",
      "End of video.\n",
      "Video ID: 65300, Total Frames: 64\n",
      "End of video.\n",
      "Video ID: 08915, Total Frames: 94\n",
      "End of video.\n",
      "Video ID: 08925, Total Frames: 42\n",
      "End of video.\n",
      "Video ID: 65415, Total Frames: 70\n",
      "End of video.\n",
      "Video ID: 13647, Total Frames: 79\n",
      "End of video.\n",
      "Video ID: 13648, Total Frames: 70\n",
      "End of video.\n",
      "Video ID: 13631, Total Frames: 71\n",
      "End of video.\n",
      "Video ID: 13632, Total Frames: 71\n",
      "End of video.\n",
      "Video ID: 13633, Total Frames: 94\n",
      "End of video.\n",
      "Video ID: 13634, Total Frames: 96\n",
      "End of video.\n",
      "Video ID: 13635, Total Frames: 106\n",
      "End of video.\n",
      "Video ID: 13636, Total Frames: 131\n",
      "End of video.\n",
      "Video ID: 13630, Total Frames: 106\n",
      "End of video.\n",
      "Video ID: 13640, Total Frames: 59\n",
      "End of video.\n",
      "Video ID: 13641, Total Frames: 43\n",
      "End of video.\n",
      "Video ID: 13642, Total Frames: 40\n",
      "End of video.\n",
      "Video ID: 13646, Total Frames: 72\n",
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "with mpHolistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for action, videos in zip(actions, wlasl_df['video_ids']):\n",
    "        for sequence, video_id in enumerate(videos):\n",
    "            video_path = f\"A:\\\\archive (1)\\\\videos\\\\{video_id}.mp4\"\n",
    "            cap = cv.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Error opening video file: {video_path}\")\n",
    "                continue\n",
    "            \n",
    "            total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "            print(f\"Video ID: {video_id}, Total Frames: {total_frames}\")\n",
    "\n",
    "            i = 0\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"End of video.\")\n",
    "                    break\n",
    "\n",
    "                # Process each frame using MediaPipe Holistic\n",
    "                image, results = mediapipeDetection(frame, holistic)\n",
    "                drawStyledLandmarks(image, results)\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npyPath = os.path.join(DATA_PATH, action, str(sequence), str(i))\n",
    "                np.save(npyPath, keypoints)\n",
    "                i += 1\n",
    "\n",
    "                cv.imshow(\"OpenCV Feed\", image)\n",
    "                if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "                # Check for \"Quit\" button press (Press 'q' to quit)\n",
    "                if cv.waitKey(10) & 0xFF == ord('Q'):\n",
    "                    cap.release()\n",
    "                    cv.destroyAllWindows()\n",
    "                    exit()\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
